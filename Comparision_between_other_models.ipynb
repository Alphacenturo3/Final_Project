{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comarision_between_other_models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zFxCvw0sajj"
      },
      "outputs": [],
      "source": [
        "#I have used 6 change it in 2nd block\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a pipeline that standardizes the data then creates a model\n",
        "#Load libraries for data processing\n",
        "import pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cross_validation import cross_val_score, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "# visualization\n",
        "import seaborn as sns \n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8,4) \n",
        "#plt.rcParams['axes.titlesize'] = 'large'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "data = pd.read_csv('data/clean-data.csv', index_col=False)\n",
        "data.drop('Unnamed: 0',axis=1, inplace=True)\n",
        "\n",
        "# Split-out validation dataset\n",
        "array = data.values\n",
        "X = array[:,1:31]\n",
        "y = array[:,0]\n",
        "\n",
        "# Divide records in training and testing sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "\n",
        "#transform the class labels from their original string representation (M and B) into integers\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "2.0 Evaluate Algorithms: Baseline\n",
        "# Spot-Check Algorithms\n",
        "models = []\n",
        "models.append(( 'LR' , LogisticRegression()))\n",
        "models.append(( 'LDA' , LinearDiscriminantAnalysis()))\n",
        "models.append(( 'KNN' , KNeighborsClassifier()))\n",
        "models.append(( 'CART' , DecisionTreeClassifier()))\n",
        "models.append(( 'NB' , GaussianNB()))\n",
        "models.append(( 'SVM' , SVC()))\n",
        "\n",
        "# Test options and evaluation metric\n",
        "num_folds = 10\n",
        "num_instances = len(X_train)\n",
        "seed = 7 \n",
        "scoring =  'accuracy'\n",
        "\n",
        "# Test options and evaluation metric\n",
        "num_folds = 10\n",
        "num_instances = len(X_train)\n",
        "seed = 7 \n",
        "scoring =  'accuracy'\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        " kfold = KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
        " cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        " results.append(cv_results)\n",
        " names.append(name)\n",
        " msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        " print(msg)\n",
        "print('-> 10-Fold cross-validation accurcay score for the training data for six classifiers') "
      ],
      "metadata": {
        "id": "zIht_RwcbMcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "id": "Tn8I2qKNbMfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Algo \n",
        "fig = plt.figure()\n",
        "fig.suptitle( 'Algorithm Comparison' )\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YGLYO1pBbMik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipelines = []\n",
        "pipelines.append(( 'ScaledLR' , Pipeline([( 'Scaler' , StandardScaler()),( 'LR' ,\n",
        "    LogisticRegression())])))\n",
        "pipelines.append(( 'ScaledLDA' , Pipeline([( 'Scaler' , StandardScaler()),( 'LDA' ,\n",
        "    LinearDiscriminantAnalysis())])))\n",
        "pipelines.append(( 'ScaledKNN' , Pipeline([( 'Scaler' , StandardScaler()),( 'KNN' ,\n",
        "    KNeighborsClassifier())])))\n",
        "pipelines.append(( 'ScaledCART' , Pipeline([( 'Scaler' , StandardScaler()),( 'CART' ,\n",
        "    DecisionTreeClassifier())])))\n",
        "pipelines.append(( 'ScaledNB' , Pipeline([( 'Scaler' , StandardScaler()),( 'NB' ,\n",
        "    GaussianNB())])))\n",
        "pipelines.append(( 'ScaledSVM' , Pipeline([( 'Scaler' , StandardScaler()),( 'SVM' , SVC())])))\n",
        "\n",
        "results = []\n",
        "names = []\n",
        "for name, model in pipelines:\n",
        "  kfold = KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
        "  cv_results = cross_val_score(model, X_train, y_train, cv=kfold,\n",
        "      scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ],
      "metadata": {
        "id": "ICZtHX1abMlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "fig.suptitle( 'Scaled Algorithm Comparison' )\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()\n",
        "#it will visualise comparision"
      ],
      "metadata": {
        "id": "EU-o6kBYbMmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_svc = Pipeline([('scl', StandardScaler()),\n",
        "                     ('pca', PCA(n_components=2)),\n",
        "                     ('clf', SVC(probability=True, verbose=False))])\n",
        "\n",
        "#Fit Pipeline to training Data\n",
        "pipe_svc.fit(X_train, y_train)\n",
        "\n",
        "#print('--> Fitted Pipeline to training Data')\n",
        "\n",
        "scores = cross_val_score(estimator=pipe_svc, X=X_train, y=y_train, cv=10, n_jobs=1, verbose=0)\n",
        "print('--> Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
        "\n",
        "#Tune Hyperparameters\n",
        "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
        "param_grid = [{'clf__C': param_range,'clf__kernel': ['linear']},\n",
        "              {'clf__C': param_range,'clf__gamma': param_range,\n",
        "               'clf__kernel': ['rbf']}]\n",
        "gs_svc = GridSearchCV(estimator=pipe_svc,\n",
        "                  param_grid=param_grid,\n",
        "                  scoring='accuracy',\n",
        "                  cv=10,\n",
        "                  n_jobs=1)\n",
        "gs_svc = gs_svc.fit(X_train, y_train)\n",
        "print('--> Tuned Parameters Best Score: ',gs.best_score_)\n",
        "print('--> Best Parameters: \\n',gs.best_params_)\n",
        "#it will take some time"
      ],
      "metadata": {
        "id": "wrTOOGNPbMo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use best parameters\n",
        "clf_svc = gs.best_estimator_\n",
        "\n",
        "#Get Final Scores\n",
        "clf_svc.fit(X_train, y_train)\n",
        "scores = cross_val_score(estimator=clf_svc,\n",
        "                         X=X_train,\n",
        "                         y=y_train,\n",
        "                         cv=10,\n",
        "                         n_jobs=1)\n",
        "print('--> Final Model Training Accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))\n",
        "\n",
        "print('--> Final Accuracy on Test set: %.5f' % clf_svc.score(X_test,y_test))"
      ],
      "metadata": {
        "id": "FGwYlt_fa0Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Score \n",
        "clf_svc.fit(X_train, y_train)\n",
        "y_pred = clf_svc.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "n-rfz8l3a0HK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}